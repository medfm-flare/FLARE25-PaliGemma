{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "NOgOex9273L_"
   },
   "source": [
    "# FLARE25-PaliGemma: Evaluation Notebook\n",
    "\n",
    "This notebook adapts the provided python script for evaluation into a step-by-step Jupyter Notebook environment.\n",
    "\n",
    "This evaluation notebook supports all FLARE25 task types with specialized metrics:\n",
    "1. **Classification**: Balanced Accuracy\n",
    "2. **Multi-label Classification**: F1-Score (micro-average)\n",
    "3. **Detection / Instance Detection**: F1-Score (with IoU>0.5 threshold)\n",
    "4. **Counting / Regression**: Mean Absolute Error (MAE)\n",
    "5. **Report Generation**: GREEN Score\n",
    "\n",
    "We will break down the script into logical sections and execute them step by step in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "E6_Zjgyz73MA"
   },
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "Install and import all required libraries for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e602d92b",
    "outputId": "a7a7242d-31cd-495f-bab5-3c5ebff8b498"
   },
   "source": [
    "!pip install scikit-learn"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afc089a9",
    "outputId": "ed616c9f-cd0a-46a4-c016-6e10a5a1d275"
   },
   "source": [
    "!git clone https://github.com/Stanford-AIMI/GREEN.git\n",
    "%cd GREEN\n",
    "!pip install -e ."
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'GREEN'...\n",
      "remote: Enumerating objects: 380, done.\u001b[K\n",
      "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
      "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
      "remote: Total 380 (delta 115), reused 202 (delta 93), pack-reused 138 (from 1)\u001b[K\n",
      "Receiving objects: 100% (380/380), 278.12 KiB | 14.64 MiB/s, done.\n",
      "Resolving deltas: 100% (143/143), done.\n",
      "/content/GREEN\n",
      "Obtaining file:///content/GREEN\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch==2.2.2 (from green_score==0.0.11)\n",
      "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting transformers==4.40.0 (from green_score==0.0.11)\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.30.1 (from green_score==0.0.11)\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pillow==10.3.0 (from green_score==0.0.11)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (0.2.0)\n",
      "Collecting sentence-transformers==3.0.1 (from green_score==0.0.11)\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting datasets==3.2.0 (from green_score==0.0.11)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torchvision==0.17.2 (from green_score==0.0.11)\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting opencv-python==4.10.0.84 (from green_score==0.0.11)\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting dill==0.3.8 (from green_score==0.0.11)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting protobuf==5.29.1 (from green_score==0.0.11)\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (1.15.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (1.6.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (2.2.2)\n",
      "Collecting numpy<2 (from green_score==0.0.11)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from green_score==0.0.11) (8.3.5)\n",
      "INFO: pip is looking at multiple versions of green-score to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Package 'green-score' requires a different Python: 3.11.13 not in '==3.12.1'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RAzSguuv73MB"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import ast\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error, balanced_accuracy_score\n",
    "from green_score import GREEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "PkGtTjit73MB"
   },
   "source": [
    "## 2. Evaluation Configuration\n",
    "\n",
    "Configure the evaluation parameters:\n",
    "- **Dataset Path**: Path to FLARE25 validation dataset\n",
    "- **Prediction File**: JSON file with model predictions\n",
    "- **Output Settings**: Where to save evaluation results\n",
    "- **Task Settings**: Which tasks to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUQ2Bmrf73MC",
    "outputId": "9b9f084b-af22-4746-e71d-713232ee341e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation Configuration:\n",
      "  Dataset Path: original_dataset\n",
      "  Prediction File: predictions_public.json\n",
      "  Output Directory: evaluation_results\n",
      "  Metrics File: metrics_public.json\n"
     ]
    }
   ],
   "source": [
    "# Configure evaluation settings\n",
    "class EvalArgs:\n",
    "    def __init__(self):\n",
    "        # Dataset configuration\n",
    "        self.base_dataset_path = \"original_dataset\"  # FLARE25 dataset directory\n",
    "        self.prediction_file = \"predictions_public.json\"  # Model predictions\n",
    "\n",
    "        # Output configuration\n",
    "        self.output_dir = \"evaluation_results\"\n",
    "        self.output_filename = \"metrics_public.json\"\n",
    "\n",
    "        # Evaluation settings\n",
    "        self.verbose = True  # Detailed output\n",
    "\n",
    "args = EvalArgs()\n",
    "\n",
    "print(\"Evaluation Configuration:\")\n",
    "print(f\"  Dataset Path: {args.base_dataset_path}\")\n",
    "print(f\"  Prediction File: {args.prediction_file}\")\n",
    "print(f\"  Output Directory: {args.output_dir}\")\n",
    "print(f\"  Metrics File: {args.output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "KFmi5-Lh73MC"
   },
   "source": [
    "## 3. Data Loading and Processing Utilities\n",
    "\n",
    "Essential functions for handling FLARE25 dataset:\n",
    "- **File Discovery**: Find all JSON files in validation directory\n",
    "- **Data Loading**: Load and merge multiple JSON files\n",
    "- **Sample Matching**: Create unique keys for matching predictions with ground truth\n",
    "- **Validation**: Ensure all required files exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n8PkaCvy73MD"
   },
   "outputs": [],
   "source": [
    "def find_json_files(base_path):\n",
    "    \"\"\"Recursively find all JSON files in the specified directory.\"\"\"\n",
    "    json_files = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_files.append(os.path.join(root, file))\n",
    "    return json_files\n",
    "\n",
    "\n",
    "def load_and_merge_json_files(json_files):\n",
    "    \"\"\"Load and merge multiple JSON files into a single list.\"\"\"\n",
    "    all_data = []\n",
    "    dataset_info = {}\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    all_data.extend(data)\n",
    "                    dataset_info[os.path.basename(json_file)] = len(data)\n",
    "                else:\n",
    "                    all_data.append(data)\n",
    "                    dataset_info[os.path.basename(json_file)] = 1\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load {json_file}: {e}\")\n",
    "\n",
    "    return all_data, dataset_info\n",
    "\n",
    "\n",
    "def create_sample_key(sample):\n",
    "    \"\"\"Create a unique key for matching samples between ground truth and predictions.\"\"\"\n",
    "    image_name = str(sample.get(\"ImageName\", sample.get(\"image\", \"\")))\n",
    "    question = str(sample.get(\"Question\", \"\"))\n",
    "    return f\"{image_name}||{question}\"\n",
    "\n",
    "\n",
    "def validate_paths(ground_truth_path, prediction_file):\n",
    "    \"\"\"Validate that required paths exist and contain data.\"\"\"\n",
    "    # Check ground truth path\n",
    "    if not os.path.exists(ground_truth_path):\n",
    "        raise FileNotFoundError(f\"Ground truth dataset directory not found: {ground_truth_path}\")\n",
    "\n",
    "    # Find JSON files in ground truth path\n",
    "    gt_files = find_json_files(ground_truth_path)\n",
    "    if not gt_files:\n",
    "        raise FileNotFoundError(f\"No JSON files found in {ground_truth_path}\")\n",
    "\n",
    "    # Check prediction file\n",
    "    if not os.path.exists(prediction_file):\n",
    "        raise FileNotFoundError(f\"Prediction file not found: {prediction_file}\")\n",
    "\n",
    "    return gt_files, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "l0mGssOl73MD"
   },
   "source": [
    "## 4. Task-Specific Metric Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TWE-0Opu73MD"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(bbox1, bbox2):\n",
    "    \"\"\"Calculate Intersection over Union (IoU) between two bounding boxes.\"\"\"\n",
    "    try:\n",
    "        x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "        x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "\n",
    "        # Calculate intersection coordinates\n",
    "        x_left = max(x1_min, x2_min)\n",
    "        y_top = max(y1_min, y2_min)\n",
    "        x_right = min(x1_max, x2_max)\n",
    "        y_bottom = min(y1_max, y2_max)\n",
    "\n",
    "        # Check if there's no intersection\n",
    "        if x_right <= x_left or y_bottom <= y_top:\n",
    "            return 0.0\n",
    "\n",
    "        # Calculate areas\n",
    "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "        bbox1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "        bbox2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "        union_area = bbox1_area + bbox2_area - intersection_area\n",
    "\n",
    "        return intersection_area / union_area if union_area > 0 else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def safe_float_conversion(value):\n",
    "    \"\"\"Safely convert value to float for numeric tasks.\"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for consistent comparison.\"\"\"\n",
    "    return str(text).strip().lower() if text is not None else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "JOGVuUI873MD"
   },
   "source": [
    "### 4.1 Classification Metrics\n",
    "\n",
    "$$ \\text{Balanced Accuracy} = \\frac{1}{C}\\sum_{i = 1}^C \\frac{TP_i}{TP_i + FN_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "U-z9hJVv73MD"
   },
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(predictions, ground_truth):\n",
    "    \"\"\"Calculate balanced accuracy for single-label classification tasks.\"\"\"\n",
    "    normalized_gt = [normalize_text(ref) for ref in ground_truth]\n",
    "    normalized_pred = [normalize_text(pred) for pred in predictions]\n",
    "\n",
    "    return {\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(normalized_gt, normalized_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rglk6qWe73MD"
   },
   "source": [
    "### 4.2 Multi-label Classification Metrics\n",
    "\n",
    "$$\n",
    "Precision_{micro} = \\frac{\\sum_i TP_i}{ \\sum_i TP_i + \\sum_i FP_i }, \\quad Recall_{micro} = \\frac{\\sum_i TP_i}{ \\sum_i TP_i + \\sum_i FN_i }\n",
    "$$\n",
    "\n",
    "$$\n",
    "F1_{micro} = 2 \\cdot \\frac{Precision_{micro} \\cdot Recall_{micro}}{Precision_{micro} + Recall_{micro}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "axinYEXf73ME"
   },
   "outputs": [],
   "source": [
    "def calculate_multilabel_metrics(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculate F1-score for multi-label classification tasks.\n",
    "    Labels are separated by semicolons.\n",
    "    \"\"\"\n",
    "    true_positives = false_positives = false_negatives = 0\n",
    "\n",
    "    for pred, gt in zip(predictions, ground_truth):\n",
    "        if isinstance(pred, str) and isinstance(gt, str):\n",
    "            # Parse labels (semicolon or comma separated)\n",
    "            pred_labels = set(label.strip().lower() for label in re.split(r'[;]', pred) if label.strip())\n",
    "            gt_labels = set(label.strip().lower() for label in re.split(r'[;]', gt) if label.strip())\n",
    "\n",
    "            # Calculate confusion matrix components\n",
    "            true_positives += len(pred_labels & gt_labels)\n",
    "            false_positives += len(pred_labels - gt_labels)\n",
    "            false_negatives += len(gt_labels - pred_labels)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"f1_score\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "zl695hBw73ME"
   },
   "source": [
    "### 4.3 Detection Metrics\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}, \\quad Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QRvX6hO773ME"
   },
   "outputs": [],
   "source": [
    "def calculate_detection_metrics(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculate F1-score for object detection tasks.\n",
    "    Matches predictions to ground truth using IoU > 0.5 threshold.\n",
    "    \"\"\"\n",
    "    true_positives = false_positives = false_negatives = 0\n",
    "\n",
    "    for pred, gt in zip(predictions, ground_truth):\n",
    "        try:\n",
    "            # Parse JSON strings to lists\n",
    "            if isinstance(gt, str):\n",
    "                gt = ast.literal_eval(gt)\n",
    "            if isinstance(pred, str):\n",
    "                pred = ast.literal_eval(pred)\n",
    "\n",
    "            if not isinstance(pred, list):\n",
    "                false_negatives += len(gt)\n",
    "                continue\n",
    "\n",
    "            matched_predictions = set()\n",
    "\n",
    "            # For each ground truth box, find best matching prediction\n",
    "            for gt_bbox in gt:\n",
    "                best_iou, best_idx = 0.0, -1\n",
    "\n",
    "                for idx, pred_bbox in enumerate(pred):\n",
    "                    if idx in matched_predictions:\n",
    "                        continue\n",
    "                    iou = calculate_iou(gt_bbox, pred_bbox)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou, best_idx = iou, idx\n",
    "\n",
    "                if best_iou > 0.5:  # IoU threshold\n",
    "                    true_positives += 1\n",
    "                    matched_predictions.add(best_idx)\n",
    "                else:\n",
    "                    false_negatives += 1\n",
    "\n",
    "            # Unmatched predictions are false positives\n",
    "            false_positives += len(pred) - len(matched_predictions)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"detection_f1\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Rwra66l73ME"
   },
   "source": [
    "### 4.4 Instance Detection Metrics\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}, \\quad Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cx0G_NQ173ME"
   },
   "outputs": [],
   "source": [
    "def calculate_instance_detection_metrics(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculate F1-score for instance detection tasks.\n",
    "    Handles class-aware detection with IoU matching.\n",
    "    \"\"\"\n",
    "    true_positives = false_positives = false_negatives = 0\n",
    "\n",
    "    for pred, gt in zip(predictions, ground_truth):\n",
    "        try:\n",
    "            # Parse JSON strings to dictionaries\n",
    "            if isinstance(gt, str):\n",
    "                gt = json.loads(gt)\n",
    "            if isinstance(pred, str):\n",
    "                pred = json.loads(pred)\n",
    "\n",
    "            if not isinstance(pred, dict):\n",
    "                # Count all ground truth instances as false negatives\n",
    "                total_fn = sum(len(v) for v in gt.values() if isinstance(v, list))\n",
    "                false_negatives += total_fn\n",
    "                continue\n",
    "\n",
    "            # Process each class separately\n",
    "            all_classes = set(gt.keys()) | set(pred.keys())\n",
    "\n",
    "            for class_name in all_classes:\n",
    "                gt_bboxes = gt.get(class_name, [])\n",
    "                pred_bboxes = pred.get(class_name, [])\n",
    "\n",
    "                # Hungarian matching algorithm (simplified)\n",
    "                gt_matched = set()\n",
    "                pred_matched = set()\n",
    "\n",
    "                # Create IoU matrix\n",
    "                iou_matrix = [[calculate_iou(gt_box, pred_box)\n",
    "                              for pred_box in pred_bboxes]\n",
    "                              for gt_box in gt_bboxes]\n",
    "\n",
    "                # Greedy matching with IoU > 0.5\n",
    "                while True:\n",
    "                    max_iou, max_gt_idx, max_pred_idx = -1, -1, -1\n",
    "\n",
    "                    for i, row in enumerate(iou_matrix):\n",
    "                        if i in gt_matched:\n",
    "                            continue\n",
    "                        for j, iou_value in enumerate(row):\n",
    "                            if j in pred_matched:\n",
    "                                continue\n",
    "                            if iou_value > max_iou:\n",
    "                                max_iou, max_gt_idx, max_pred_idx = iou_value, i, j\n",
    "\n",
    "                    if max_iou >= 0.5:\n",
    "                        true_positives += 1\n",
    "                        gt_matched.add(max_gt_idx)\n",
    "                        pred_matched.add(max_pred_idx)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                false_negatives += len(gt_bboxes) - len(gt_matched)\n",
    "                false_positives += len(pred_bboxes) - len(pred_matched)\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"instance_f1\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "j3ZhyqhD73ME"
   },
   "source": [
    "### 4.5 Regression, Counting Metrics\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{i = 1}^N |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ y_i $: ground truth value\n",
    "- $ \\hat{y}_i $: predicted value\n",
    "- $ N $: number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5GKinT7373MF"
   },
   "outputs": [],
   "source": [
    "def calculate_regression_metrics(predictions, ground_truth):\n",
    "    \"\"\"Calculate Mean Absolute Error for regression and counting tasks.\"\"\"\n",
    "    gt_floats = [safe_float_conversion(x) for x in ground_truth]\n",
    "    pred_floats = [safe_float_conversion(x) for x in predictions]\n",
    "\n",
    "    # Filter out invalid conversions\n",
    "    valid_pairs = [(pred, gt) for pred, gt in zip(pred_floats, gt_floats)\n",
    "                   if pred is not None and gt is not None]\n",
    "\n",
    "    if not valid_pairs:\n",
    "        return {\"mean_absolute_error\": None}\n",
    "\n",
    "    preds, gts = zip(*valid_pairs)\n",
    "    mae = mean_absolute_error(gts, preds)\n",
    "\n",
    "    return {\n",
    "        \"mean_absolute_error\": mae,\n",
    "        \"valid_samples\": len(valid_pairs),\n",
    "        \"total_samples\": len(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-w9hSAG73MF"
   },
   "source": [
    "### 4.6 Report Generation Metrics\n",
    "\n",
    "$$\n",
    "GREEN = \\frac{\\# \\ matched \\ findings }{ \\# \\ matched \\ findings + \\sum_{i = (a)}^{(f)} error_{sig,i}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **(a)** False report of a finding in the candidate\n",
    "- **(b)** Missing a finding present in the reference\n",
    "- **(c)** Misidentification of a finding\u2019s anatomic location/position\n",
    "- **(d)** Misassessment of the severity of a finding\n",
    "- **(e)** Mentioning a comparison that isn\u2019t in the reference\n",
    "- **(f)** Omitting a comparison detailing a change from a prior study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xDLH8cxN73MF"
   },
   "outputs": [],
   "source": [
    "def calculate_report_generation_metrics(predictions, ground_truth):\n",
    "    \"\"\"Calculate GREEN Score for medical report generation tasks.\"\"\"\n",
    "    try:\n",
    "        green_model_id = \"StanfordAIMI/GREEN-radllama2-7b\"\n",
    "        green_scorer = GREEN(green_model_id, output_dir=\".\")\n",
    "        mean, _, _, _, _ = green_scorer(ground_truth, predictions)\n",
    "        return {\"green_score\": mean}\n",
    "    except Exception as e:\n",
    "        return {\"green_score\": None, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "xT1LlIiA73MF"
   },
   "source": [
    "## 5. Task Dispatcher and Data Loading\n",
    "\n",
    "### 5.1 Task Dispatcher\n",
    "Routes each task type to its appropriate metric calculation function based on the TaskType field in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "q4liXpCX73MF"
   },
   "outputs": [],
   "source": [
    "def calculate_task_metrics(predictions, ground_truth, task_type):\n",
    "    \"\"\"Calculate appropriate metrics based on task type.\"\"\"\n",
    "    task_type_normalized = task_type.lower().strip()\n",
    "\n",
    "    # Route to appropriate metric calculation function\n",
    "    if task_type_normalized == \"classification\":\n",
    "        return calculate_classification_metrics(predictions, ground_truth)\n",
    "    elif task_type_normalized == \"multi-label classification\":\n",
    "        return calculate_multilabel_metrics(predictions, ground_truth)\n",
    "    elif task_type_normalized == \"detection\":\n",
    "        return calculate_detection_metrics(predictions, ground_truth)\n",
    "    elif task_type_normalized in (\"regression\", \"counting\"):\n",
    "        return calculate_regression_metrics(predictions, ground_truth)\n",
    "    elif task_type_normalized == \"instance_detection\":\n",
    "        return calculate_instance_detection_metrics(predictions, ground_truth)\n",
    "    elif task_type_normalized in (\"report_generation\", \"report generation\"):\n",
    "        return calculate_report_generation_metrics(predictions, ground_truth)\n",
    "    else:\n",
    "        print(f\"Unknown task type: {task_type}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "id": "pIEN35QI73MF"
   },
   "source": [
    "### 5.2 Load and Match Data\n",
    "\n",
    "Load ground truth and prediction data, then match samples for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9ZwpxAG73MF",
    "outputId": "2834469d-129f-41e9-ce12-97bbf448e0ba"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading and validating data files...\n",
      "Ground truth path: /content/drive/MyDrive/flare/organized_dataset/validation-public\n",
      "Found 12 ground truth JSON files\n",
      "   Ground truth files:\n",
      "     - Xray/IU_XRay/IU_XRay_questions_val.json\n",
      "     - Xray/chestdr/chestdr_questions_val.json\n",
      "     - Endoscopy/endo/endo_questions_val.json\n",
      "     - Clinical/neojaundice/neojaundice_questions_val.json\n",
      "     - Mammography/CMMD/CMMD_questions_val.json\n",
      "     - Retinography/retino/retino_questions_val.json\n",
      "     - Ultrasound/BUSI-det/BUSI-det_questions_val.json\n",
      "     - Ultrasound/BUSI/BUSI_questions_val.json\n",
      "     - Ultrasound/BUS-UCLM/BUS-UCLM_questions_val.json\n",
      "     - Ultrasound/BUS-UCLM-det/BUS-UCLM-det_questions_val.json\n",
      "     - Microscopy/neurips22cell/neurips22cell_questions_val.json\n",
      "     - Dermatology/bcn20000/bcn20000_questions_val.json\n",
      "\n",
      "Loading ground truth data...\n",
      "Total ground truth samples: 5577\n",
      "   Dataset breakdown:\n",
      "     - IU_XRay_questions_val.json: 1945 samples\n",
      "     - chestdr_questions_val.json: 970 samples\n",
      "     - endo_questions_val.json: 16 samples\n",
      "     - neojaundice_questions_val.json: 149 samples\n",
      "     - CMMD_questions_val.json: 910 samples\n",
      "     - retino_questions_val.json: 279 samples\n",
      "     - BUSI-det_questions_val.json: 130 samples\n",
      "     - BUSI_questions_val.json: 156 samples\n",
      "     - BUS-UCLM_questions_val.json: 161 samples\n",
      "     - BUS-UCLM-det_questions_val.json: 45 samples\n",
      "     - neurips22cell_questions_val.json: 100 samples\n",
      "     - bcn20000_questions_val.json: 716 samples\n",
      "\n",
      "Loading prediction data from /content/predictions_public.json...\n",
      "Total prediction samples: 5577\n",
      "\n",
      "Matching samples between ground truth and predictions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and validating data files...\")\n",
    "\n",
    "# Construct ground truth dataset path\n",
    "gt_dataset_path = os.path.join(args.base_dataset_path, \"validation-public\")\n",
    "print(f\"Ground truth path: {gt_dataset_path}\")\n",
    "\n",
    "# Validate paths and discover files\n",
    "try:\n",
    "    gt_files, _ = validate_paths(gt_dataset_path, args.prediction_file)\n",
    "    print(f\"Found {len(gt_files)} ground truth JSON files\")\n",
    "\n",
    "    if args.verbose:\n",
    "        print(\"   Ground truth files:\")\n",
    "        for file in gt_files:\n",
    "            print(f\"     - {os.path.relpath(file, gt_dataset_path)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Path validation failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load ground truth data\n",
    "print(f\"\\nLoading ground truth data...\")\n",
    "ground_truth_data, gt_dataset_info = load_and_merge_json_files(gt_files)\n",
    "print(f\"Total ground truth samples: {len(ground_truth_data)}\")\n",
    "\n",
    "if args.verbose:\n",
    "    print(\"   Dataset breakdown:\")\n",
    "    for filename, count in gt_dataset_info.items():\n",
    "        print(f\"     - {filename}: {count} samples\")\n",
    "\n",
    "# Load prediction data\n",
    "print(f\"\\nLoading prediction data from {args.prediction_file}...\")\n",
    "try:\n",
    "    with open(args.prediction_file, 'r') as f:\n",
    "        prediction_data = json.load(f)\n",
    "    print(f\"Total prediction samples: {len(prediction_data)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load predictions: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nMatching samples between ground truth and predictions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmNoLxCQ73MF",
    "outputId": "f9df2777-8d1d-421c-b680-58eaac480e5d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd0d Sample matching statistics:\n",
      "   GT lookup size: 5577\n",
      "   Pred lookup size: 5577\n",
      "\n",
      "\ud83d\udcc8 Matching Results:\n",
      "   \u2705 Successfully matched: 5577 samples\n",
      "   \u274c Unmatched samples: 0\n",
      "\n",
      "\ud83d\udccb Task Type Distribution:\n",
      "   classification: 2843/2843 (100.0%)\n",
      "   counting: 100/100 (100.0%)\n",
      "   detection: 175/175 (100.0%)\n",
      "   multi-label classification: 514/514 (100.0%)\n",
      "   report_generation: 1945/1945 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create lookup dictionaries for efficient matching\n",
    "gt_lookup = {create_sample_key(sample): sample for sample in ground_truth_data}\n",
    "pred_lookup = {create_sample_key(sample): sample for sample in prediction_data}\n",
    "\n",
    "print(f\"\ud83d\udd0d Sample matching statistics:\")\n",
    "print(f\"   GT lookup size: {len(gt_lookup)}\")\n",
    "print(f\"   Pred lookup size: {len(pred_lookup)}\")\n",
    "\n",
    "# Group data by task type and match samples\n",
    "task_type_to_gt = defaultdict(list)\n",
    "task_type_to_pred = defaultdict(list)\n",
    "task_type_counts = defaultdict(int)\n",
    "\n",
    "matched_samples = 0\n",
    "unmatched_samples = 0\n",
    "task_type_distribution = defaultdict(int)\n",
    "\n",
    "for sample_key, gt_sample in gt_lookup.items():\n",
    "    task_type = gt_sample.get(\"TaskType\", \"\").strip().lower()\n",
    "\n",
    "    if not task_type:\n",
    "        continue\n",
    "\n",
    "    task_type_distribution[task_type] += 1\n",
    "\n",
    "    pred_sample = pred_lookup.get(sample_key)\n",
    "    if pred_sample is None:\n",
    "        unmatched_samples += 1\n",
    "        continue\n",
    "\n",
    "    gt_answer = gt_sample.get(\"Answer\", \"\")\n",
    "    pred_answer = pred_sample.get(\"Answer\", \"\")\n",
    "\n",
    "    task_type_to_gt[task_type].append(gt_answer)\n",
    "    task_type_to_pred[task_type].append(pred_answer)\n",
    "    task_type_counts[task_type] += 1\n",
    "    matched_samples += 1\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Matching Results:\")\n",
    "print(f\"   \u2705 Successfully matched: {matched_samples} samples\")\n",
    "print(f\"   \u274c Unmatched samples: {unmatched_samples}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Task Type Distribution:\")\n",
    "for task_type in sorted(task_type_distribution.keys()):\n",
    "    total = task_type_distribution[task_type]\n",
    "    matched = task_type_counts[task_type]\n",
    "    match_rate = (matched / total * 100) if total > 0 else 0\n",
    "    print(f\"   {task_type}: {matched}/{total} ({match_rate:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "93d86ddd9aab4676bbe297387cb4a5f2",
      "c9b1f26518d841b784c3760db8233b80",
      "b5f316ba66ad4f358f98e52e8962627b",
      "5172a19d001a4194ab47ee6594e1d6a6",
      "5d431aaa89ed4ef2914fb6b7c8d8f24d",
      "87557d25efca402f834f6554bfde60cf",
      "382ffd579baf41839c25628785930312",
      "3d64d907349947c8acb1223ab231dc10",
      "e6be6e0e361e4d99964a722d7496e6f2",
      "9b75859fa1a9488b97137c149c6bca14",
      "415fb951e63b467582a579f79fca6e7d",
      "9d5f699883264368823a641565fc8ec7",
      "c77fcf8b24b14f6498366a0556810df7",
      "1eb465b4a8c34c85868bac076e5d7ae1",
      "3013d17c81de4eb2888d6ae9d00f390a",
      "153734d5783e4e91ac33684222f49a14",
      "3e4f3580a427424fa133b8d909ce80f1",
      "d63f66fb42484271b162438461e18575",
      "aec97b31a65a42599163bd438faf95a3",
      "52e1b78a267147429404002052ff571f",
      "d39787adb05f41289d5477f6230d4f3b",
      "40248dc2cffd4c62b459840e43ae286e",
      "2385579ab1b5411ab49fb9f9af7d37a0",
      "494db02031b5417ab933d0bb2eebb41e",
      "ef3887b4ba33470a95ec9121f51006bb",
      "1cec9d9da8fc4846b1dd69accf66676a",
      "1a22a57e12a04f25ad7787e143cbd098",
      "ee326fe264864882bad3d5afe75c5272",
      "7705d72f3aa14d40b160f6f5db9d366e",
      "6883db859cf24341ac728aca68bf4c7f",
      "aa79df6c11504b1b8312f1da1130f65d",
      "42f4652ac4fa4762887061f615ba4acc",
      "bb98de5c9a364290b484491b03ae2059",
      "51f9f658fb174f7495fee72d8311a3d7",
      "d7638a6573134fb2bc701e0f7839947e",
      "9d1d5ebb75c24b00bb747307a2661e13",
      "cbd0594d6cff4923b1b416181e01e219",
      "a5f0ea6f098243b18d76ddc5f8318774",
      "1a4ac2fb5db04f57a97931a7023aa060",
      "fde787785e7c4138831a19b3dbce9797",
      "ae83147a9bdb476fa5019f6a0a294d9c",
      "51315eec681545fc93074b517945509d",
      "673a17b1f7444f9fbfc932873c2b6805",
      "f3b531d937624d5081128d8e021c4b77",
      "baa79b58ca9840e492beb15017aa6455",
      "7dbfb5199bc7463c98b97dadede636d8",
      "01bd2b21722046ff95d17f55c1129394",
      "ff856cf0a14041c69f67c13013b34d77",
      "6c403c6e4e1341f4a1d03a8b671bafc1",
      "7280ac5053214dcb9e4c3327a360cba0",
      "fc7221d977734528be82804295e45d34",
      "dee458ec78ba41fd85438dc434a4d1fd",
      "5ba22914f2e34af7b13b7afb4a16f7a7",
      "7bcfe58600464caeb3566825bb9ca885",
      "5ccdbcba22a242088fa15c3a69b311c2",
      "a1320095c4f942929f8a48e76eebc4ef",
      "a7529c14e5694fd9b0ed9aedcedc1db1",
      "fa11ec910846453d8c90e1e3e64cff9b",
      "ee77d9a0c57a403f80371716fa4b8fe0",
      "977171b26e5740beb70a1557dd19ef8b",
      "0b27dedd445e4d83939788b74ef596b5",
      "bde93e58160c4dd8bb3200339f140bc0",
      "182ab37b309b4e4c8b9695422e5e6ab4",
      "28e55abba0444bbaa6bc03e33deef5c3",
      "53f4c404df434ad2aea95cb9879d2398",
      "107d84dbad204d1793dab7126eec39f3",
      "0ba6fb7a6e5a4ede92ff4674c373e7a4",
      "643bf0bc7d714448b597494fecfab017",
      "06199d82cb8a45109b927dcfe3f6918d",
      "c22a6a530b524358a3cae9ae5edc78f0",
      "8ac0216a230d49e0aa78d3dcb17095ef",
      "f0f5dd6b28cc404291a0749d168b7cda",
      "fde168a27a1241409109a6929c141543",
      "6f80d9673e674bf0ad431731404beab2",
      "da13528859f34e45ae078d585653b5cf",
      "e59c71bf82d943d3a37a1c7ad996426e",
      "b8c0dc5096144daf88bb6ea009ff219e",
      "64c90cf9545a40999a201d5eea9fab0b",
      "272d43539bc040d49bec771e00d320d8",
      "a5ac1e37299d447685d2bd3cae205c56",
      "5a1a8ded0b5640e7b9d28b43f58b1bf2",
      "842bc81e030c4da7bbf321c81ce5c5b0",
      "88fa28279aa5481c974db8f614cb9efa",
      "5cf78afa64624b8aafb3a9b48c09d3fd",
      "34d5b28955e2413dba7958477215d566",
      "d67474c5b801497ebb0db6af59204d83",
      "16febc7d112844cc851d0964a56d7294",
      "3b858b7d41cd422794e57ebec61d545f",
      "f099b9e888d04a1ea256115feb903b2f",
      "cb691cd3d22b4063a6384bcb8c514002",
      "db12d6de361f4ec3a84c2da7054e980b",
      "013690ffc2c540afb4367344fcab49a6",
      "043235b0bb484394aed6209df63b3501",
      "5acc45eef02b44af8936b06769bb1981",
      "a809b790e6a44c99a373b1b030077831",
      "a8faee8c2c314b5baa4ba2769acd3b7e",
      "30d094e3b8044d01ba16bc5453421e4e",
      "486942137a7140739ac322732358c10a",
      "23a3163af11c4e6ca92b33ff28ca051c",
      "5bd2ca21fba349d099e2e488adefc3e5",
      "92e53665868047d7a3078c98e8686843",
      "367a8ab6fd54477580f67aa042782329",
      "7dfc131869af488caa21ea0a254e20b9",
      "d9a6b9ef64604c678c0dc8c703c09636",
      "71cf40ce6e1f487b9b9b7b41c7915340",
      "a6612fa1db21436989f4032c0efc90a9",
      "ad27e23c3ce8449d9b403ebc83242397",
      "5b0981d375894af483477f2344943f0f",
      "53aee11f009d473db2cfdf617b15bcc2",
      "e45643bcfa394c47be1669c8690981fb",
      "3dda2055f01b4d52b3e0d3abb4d0e07b",
      "8ef92014b61e422e8bc499dc1b1e36a3",
      "2d0b0a3974474df889ad8e47ba8be7ad",
      "d037e8c5708446728435b6f0b950368e",
      "c289ee16f31c41a2a0abca16fda465ae",
      "13bb97f3f80f4a26a9b4521d990d7060",
      "d5413d357e99460f986354eb8eeb1296",
      "b7d8bc2b4be942a4a7d086f494d3a5f9",
      "f7080cb282b64d8f97b2072adbb534b1",
      "a02ee06bcbc54e7fa4aea8a1be74c89d",
      "f3a0eaa8291c49c59f1f2f5a16d39ba5",
      "c21120211a504357baa4a22c3ffd92e1",
      "cf2e706e4e424579ba6d6c3406a79a67",
      "75908ba33737445dbaffdd561cf3da45",
      "3c8fd56274ff4565be4f7ca8981a0cf7",
      "98813d9da99b4bec9b39cc8f65f0d2fd",
      "ed6090b26dfa41a8ab5a189e68969323",
      "7616fb8c37e44c6e8d3875ea1a8dfc58",
      "b20ce4be2fcd45288df1e14e8440079a",
      "60eea948d8f14c1080199624e4c236a7",
      "42238977aa7446edb08cd17fd5181919",
      "8cfec65b5e864f4daf7dffbac7ac23cf",
      "228fda8222444df3b81774e118df4db9",
      "77fa64ab58ec46b5aca0da08036022ad",
      "c4541b1f171646f58543679ae5f3383e",
      "d53bd04612694e91a20ac8f675ea3a1f",
      "30b7ae10e3b54f14ac8f4c2deb819c4a",
      "0abaabd1c1274256bfaa83b4163bb929",
      "dd61bb14486c4920b6ba80e8088b3f4b",
      "a844229b5c1441cfb8bd9271085f4281",
      "049c68c084c54b7b96ea13e52e3b3818",
      "88ecd14292704f0fa89d56c304c8fa97",
      "82256d42bd904810b88de0dd2aece57b",
      "9f8216d769514bf0b62fc34fcfa6f2c2",
      "d87b7901fab946c2898cf0f16f2cd458",
      "f4ecad9fdd5640dcbb8cb7539c43071b",
      "c27f3acb581347889e4fd908b1fce7d1",
      "000848023f6f41aaa299d554ef63c275",
      "c65e51e191804c64868b62c476548e8b",
      "2119f2a738f349a99a19f6cb08a58ce0",
      "3be7351fcd1249a9b00ec1cb5c09e852",
      "6d87c43df5a046d4bdf5374da855471a",
      "c9b8f9305ed54860996475fa870ac88a",
      "c4c5ea2c8e224c0aa625b3a99f103cdc",
      "4446f08b39f94346be9a84cb3f59c16d",
      "5571a1d9375b45ecaa43668551f26eff",
      "23281bf032e545c3bf3596370146d06b",
      "50972833e70c44d0b204f94e3fcc6105",
      "b97bfa15cbc14105956db2fab31a3739",
      "9e72ca721f784af2a794babec2d2e318",
      "fcdeb09f43924cdea6446e7bd8cac550",
      "0975c4a15a1c48529f49a2524a004d6b",
      "d77d738d61c74a86af15a3495037f437",
      "c434de4551f14391939def241ea5a6fa",
      "a19e06854c944959a583ccef7b7932f8",
      "1d4139febb1e4f2591d89c2b87ab3af4",
      "b068f7cf4fa349328c2e4cf2f10e69e1",
      "438ca5afdbe441e38161f3c7fc6edf32",
      "ed621be64b2d41cca5e09c39db5d8f07",
      "c104a56c91ec421994837b1cc78cfcea",
      "f6a137540c6e498b99e54aeb175ba00c",
      "5a36d39528b749cd98b53e93875abc97",
      "e72bf3da880547a39fe13586dc6cf00b",
      "f6d218bea0fd4dcaa1dd4d8ed40f024c",
      "9488c44d2eb243ae8a0b9ed9af023bbb",
      "4cf1097030c24e3c9578204d604cf907",
      "0707e6c954c14e6cbe8d6ae4c79cae89",
      "a8969173c03a4800ba30f729667ef257",
      "4b3eedec7a5a4c6c989d96c5380ad365",
      "2503fdd19a8e4a7e8b357975b4a6dbf3",
      "d2ef804a8f9043f1a91b24f3a4d0aa88",
      "3327e3dfe9104d71998a4c286f5fd20d",
      "a3b72829023e421392139c0c0bc1a44f",
      "543e66f1dd20406a93c615294ffabb9e",
      "0ba81b569352489b8f7cbe84c0460bfd",
      "52aa708f098a43a59ecd98a0422ce74d",
      "f312acf4063841528499dbadcb492816",
      "a5f7c006488845b494a62f879f8b1aa6",
      "db33061d0a044762a852e9735f56eb40",
      "a2e7aa71dd44485db14b99774583a45b",
      "3dea1b1cb619404a859eb33b28e94c47",
      "153ad63bd87d4b8d90eeba59e95948b1",
      "33f8b4ca02fa4ca6a31374b8af681151",
      "5cf8ed5e6c1a40f0babb88e93295cfda",
      "794da2ac406e4415ba9ad68e46dc753e",
      "5171f864c7134578ad13f916918fc5fc",
      "844fe7445638416698d6a154564e5e5b",
      "541118b4d4284d35b719a6dd80d60daa",
      "f14070d634c34243a3daa063f34fa7bf",
      "7af8061ece9f4c00b3011b83f2114a32",
      "2c5bf08a2a74409a854996c8d9ce512a",
      "59f0789028cc4bab95ce1a6791e73238",
      "1c0964fae22749688ff338a067d1ff15",
      "968964b2679045c78a6c1f6a4237e302",
      "03b2f8e5531c44dea825a35ef4c9ceef",
      "242f8ee3ca4f4bdcb9acbea30cac2023",
      "4d86a34c01914840acd4a9083d2304b8",
      "2f7ebe90d93146d3acc6b4d4392303c2",
      "6aa74462151b48448adb4fe24f632b0d",
      "59f1ebecbc354080ac6834cfd9a9655d",
      "a3dc678db8504dc0a9ef7e0ef509edce",
      "054072e9a6cf4eb59e6168b745d25574",
      "d6ba53821cea420d810e8ab34ba3186f",
      "f17bcad7a3f04087b2266e602b63aac2",
      "55dc17a1300245d08f502897f8807e8d",
      "b8d337a8c9484122b63143abc36e47f6",
      "53c04880b6434aa8bb93321324e605c1",
      "ce51a3f8a3634896a4347f5e063c80a4",
      "2eae0479d9bf4c73a756a3039754d44b",
      "bb929b944bb9454894ffcc5e49e16d88",
      "c46c241a84b5415d8494aa03dcd81727",
      "92f64fcdc599411aa8d1ac4f182bb84c",
      "e5e267f7e72744fbadea8e521b7049ca",
      "ee3e2a8c28c240459294e38fc6a6f574",
      "8d7686d7476240c8bc8a04e5163acb0c",
      "49b4cca0e5f549648860faf815011a06",
      "3b4f847ec01f4173812e4b0c086a66e2",
      "6b916ed8bfe14d08b6b310e53e052430",
      "30fa64dcfda34571b590449169878f26",
      "7f4c4d07fabe416a813315ff2db8ccb6",
      "b00f8c65fe9d4ff1afc8cf9b9ccfa1f1",
      "bbf017479373451885fec3663b56e933",
      "7f3a27cabdd44e54b68aa2d2651c57c2",
      "c2c1e1aced7b45529bcd04c3000e4bc2",
      "454a36864dc04d8b8ea9bb5c631e5f2b",
      "e3a6838e728e4f58999716714393e1e2",
      "61d7407755014ae7a04744b5d9f36d52",
      "3470fc4125534c989b3416802a39ec2f",
      "4b871998f0714a1dbac9d31bb4fccda2",
      "92932ace9bd54a79b8ccaf1b2a171aad",
      "85c47f2324124120a9dbd92e9daf8855",
      "ac3a75620c1d4fc38528beb16373e707",
      "8f539db2fccf4dc3926443ba87be68a1",
      "bf6c35cb91b345f0abbe156f64fe1d74",
      "7f4e143c00e24751ac20b4b55db00b02",
      "6a44ca56cc924ea19bffcc8860fcccac",
      "a7ea9b27666a42e4a9c3f2653960de73",
      "ddbdfad318cd461cb058432ca2ff9e57",
      "9de4277beb5741e6a014db65d5bfb7f6",
      "12e8bac9553044d3abce5512e5b614ed",
      "bdbe69e094594e7588329945b3d6cdaa",
      "b3c6c3c7e39e4cd99013a87b3b221b7b",
      "865bdad5f9a444b4ab2bd3c4be75aa3d",
      "91e981658f794f25a3d38e06ef9dc6de",
      "b483f777c7aa46cab8175d35dc27a72b",
      "8bb3f8e26df74834aa91e2a3be0f2316",
      "2f6227bc4d0c4600baa110a8ac77367b",
      "9772429c88e14bb8805c48dc302c7778",
      "c84eda1eed3448fea57f4cc61296beaa",
      "91308071531c4e2d8d6b188b798e9540",
      "a4ec21df49b146b9a4c884c9cd8bd50b",
      "2dd5fa1c55cd4c11890323cc917ae4c0",
      "42c2e2f5c5b94850bebc18a93b5fa220",
      "2844305601c04f57be1e5a598959c4b2",
      "65bb5da4f62d4288ba12bfb8f875522d",
      "fa31eb6f733f46e69bafff67f74e49e0",
      "dce3f413e1cf4e719303df0ac263ae4c",
      "1c6ac8ab07bd4bb59a397f90887e0867",
      "de98b6523a9b4ddc8755dad2132f0e02",
      "260a8c6965d9445eba5da3a9f803a439",
      "e5faff10c3bd463d850105cf775def36",
      "8f75a73604854ed5814e50aa5488389e",
      "e69341ed921c46a2927f2fcb1f0a83ef",
      "8b58db526105404bad8742a7c71245d0",
      "d678c0c480134396be12a3d6db5a72b2"
     ]
    },
    "id": "RwDq4n-073MG",
    "outputId": "5b74e76a-ba73-4800-f017-8cc78e8c9dcc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\uddee Calculating metrics by task type...\n",
      "\n",
      "\ud83d\udcca Evaluating classification:\n",
      "   Samples: 2843\n",
      "   Results:\n",
      "     balanced_accuracy: 0.2532\n",
      "\n",
      "\ud83d\udcca Evaluating counting:\n",
      "   Samples: 100\n",
      "   Results:\n",
      "     mean_absolute_error: 295.6500\n",
      "     valid_samples: 100\n",
      "     total_samples: 100\n",
      "\n",
      "\ud83d\udcca Evaluating detection:\n",
      "   Samples: 175\n",
      "   Results:\n",
      "     detection_f1: 0.1979\n",
      "     precision: 0.2022\n",
      "     recall: 0.1937\n",
      "\n",
      "\ud83d\udcca Evaluating multi-label classification:\n",
      "   Samples: 514\n",
      "   Results:\n",
      "     f1_score: 0.4437\n",
      "     precision: 0.4730\n",
      "     recall: 0.4177\n",
      "\n",
      "\ud83d\udcca Evaluating report_generation:\n",
      "   Samples: 1945\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/691 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93d86ddd9aab4676bbe297387cb4a5f2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d5f699883264368823a641565fc8ec7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2385579ab1b5411ab49fb9f9af7d37a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51f9f658fb174f7495fee72d8311a3d7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baa79b58ca9840e492beb15017aa6455"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1320095c4f942929f8a48e76eebc4ef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ba6fb7a6e5a4ede92ff4674c373e7a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64c90cf9545a40999a201d5eea9fab0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f099b9e888d04a1ea256115feb903b2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenization_chexagent.py:   0%|          | 0.00/26.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bd2ca21fba349d099e2e488adefc3e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dda2055f01b4d52b3e0d3abb4d0e07b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c21120211a504357baa4a22c3ffd92e1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "228fda8222444df3b81774e118df4db9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing data...making prompts\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1945 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f8216d769514bf0b62fc34fcfa6f2c2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done.\n",
      "==== Beginning Inference ====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "244it [2:46:50, 41.03s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== End Inference ====\n",
      "Computing summary ...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4446f08b39f94346be9a84cb3f59c16d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d4139febb1e4f2591d89c2b87ab3af4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/3.52k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0707e6c954c14e6cbe8d6ae4c79cae89"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5f7c006488845b494a62f879f8b1aa6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f14070d634c34243a3daa063f34fa7bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59f1ebecbc354080ac6834cfd9a9655d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c46c241a84b5415d8494aa03dcd81727"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbf017479373451885fec3663b56e933"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f539db2fccf4dc3926443ba87be68a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91e981658f794f25a3d38e06ef9dc6de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65bb5da4f62d4288ba12bfb8f875522d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (672) found smaller than n_clusters (675). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seconds per example:  5.173197606412795\n",
      "   Results:\n",
      "     green_score: 0.7063\n",
      "\n",
      "\ud83c\udfaf Evaluation Summary:\n",
      "   Total evaluated samples: 5577\n",
      "   Task types evaluated: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\ud83e\uddee Calculating metrics by task type...\")\n",
    "evaluation_results = {}\n",
    "total_evaluated = 0\n",
    "\n",
    "for task_type in sorted(task_type_to_gt.keys()):\n",
    "    gt_answers = task_type_to_gt[task_type]\n",
    "    pred_answers = task_type_to_pred[task_type]\n",
    "\n",
    "    print(f\"\\n\ud83d\udcca Evaluating {task_type}:\")\n",
    "    print(f\"   Samples: {len(gt_answers)}\")\n",
    "\n",
    "    # Calculate task-specific metrics\n",
    "    metrics = calculate_task_metrics(pred_answers, gt_answers, task_type)\n",
    "    metrics[\"num_examples\"] = len(gt_answers)\n",
    "    evaluation_results[task_type] = metrics\n",
    "    total_evaluated += len(gt_answers)\n",
    "\n",
    "    # Display results\n",
    "    if args.verbose:\n",
    "        print(\"   Results:\")\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if metric_name != \"num_examples\":\n",
    "                if isinstance(metric_value, float):\n",
    "                    print(f\"     {metric_name}: {metric_value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"     {metric_name}: {metric_value}\")\n",
    "    else:\n",
    "        # Show primary metric only\n",
    "        primary_metrics = {\n",
    "            \"classification\": \"balanced_accuracy\",\n",
    "            \"multi-label classification\": \"f1_score\",\n",
    "            \"detection\": \"detection_f1\",\n",
    "            \"instance_detection\": \"instance_f1\",\n",
    "            \"regression\": \"mean_absolute_error\",\n",
    "            \"counting\": \"mean_absolute_error\",\n",
    "            \"report_generation\": \"green_score\"\n",
    "        }\n",
    "\n",
    "        primary_metric = primary_metrics.get(task_type)\n",
    "        if primary_metric and primary_metric in metrics:\n",
    "            value = metrics[primary_metric]\n",
    "            if isinstance(value, float):\n",
    "                print(f\"   {primary_metric}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"   {primary_metric}: {value}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Evaluation Summary:\")\n",
    "print(f\"   Total evaluated samples: {total_evaluated}\")\n",
    "print(f\"   Task types evaluated: {len(evaluation_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fM1nN7t73MG",
    "outputId": "80038600-37c5-45ac-a299-5107905dc2bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcbe Saving evaluation results...\n",
      "\u2705 Evaluation metrics saved to: evaluation_results/metrics_public.json\n",
      "\n",
      "\ud83d\udcc1 Output file structure:\n",
      "   \ud83d\udcca Metadata: evaluation_metadata\n",
      "   \ud83d\udcc8 Metrics: task_metrics\n",
      "   \ud83d\udcc2 Location: evaluation_results/metrics_public.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\ud83d\udcbe Saving evaluation results...\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "output_file = os.path.join(args.output_dir, args.output_filename)\n",
    "\n",
    "# Add metadata to results\n",
    "final_results = {\n",
    "    \"evaluation_metadata\": {\n",
    "        \"total_samples_evaluated\": total_evaluated,\n",
    "        \"total_task_types\": len(evaluation_results),\n",
    "        \"ground_truth_path\": gt_dataset_path,\n",
    "        \"prediction_file\": args.prediction_file,\n",
    "        \"matched_samples\": matched_samples,\n",
    "        \"unmatched_samples\": unmatched_samples\n",
    "    },\n",
    "    \"task_metrics\": evaluation_results\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(final_results, f, indent=2)\n",
    "    print(f\"\u2705 Evaluation metrics saved to: {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to save results: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}